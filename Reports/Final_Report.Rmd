---
title: "IDS 702 Team Project 2: StreetRx and Voting in NC"
date: "10/25/2021"
output:
  pdf_document: default
geometry: margin=0.5in
---

# __*Part I: StreetRx*__
## __*Aarushi Verma as Programmer/Writer and Mohammad Anas as Programmer/Writer*__


```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
rm(list = ls())
library(arm)
library(pROC)
library(e1071)
library(caret)
library(ggplot2)
require(gridExtra)
library(dplyr)
library(magrittr)
library(stargazer)
library(rms)
library(ggdark)
library(ggeasy)
library(tidyverse)
library(viridis)
library(sjPlot)
library(qqplotr)
library(lme4)
```

## __Introduction__ __and__ __Summary__

StreetRx (streetrx.com) is a web-based citizen reporting tool enabling real-time collection of street price data on diverted pharmaceutical substances. Users anonymously report prices they paid for prescription drugs on the web. As part of our analysis, we built hierarchical models to investigate how location among other factors may influence the pricing per milligram of a certain drug. According to our analysis, the drug Codeine is found to cheaper in the Michigan, Missouri, Illinois and Texas states. We also found out that purchasing the drug in higher dosages and in huge quantities cad reduce the price paid for Codiene per milligram.


## __Data__

The data used in this analysis pertains to the drug, _Codeine_. We examined our data and observed missing values in columns ppm (price per milligram), mgstr (dosage strength in mg) and source (source of the reported price). We dropped the rows with missing values in ppm and mgstr column. Our original data had 4134 observations for Codeine which reduced to 3125 after missing value removal. Since the source column had high number of missing values and multiple unique values, we categorized the column into _Personal_, _Heard it_, _Internet_, _Not Indicated_. The column mgstr is a discrete variable however, it only contained 3 unique values. We created a new column called dosage to indicate the potency of the drug based on the mgstr values as low, medium or high dosage. In the state column we noted that some states had been incorrectly updated as USA hence, we replaced this value with "Others". We did not consider the form variable in our analysis since it only contained one value - pill/tablet. for the drug Codiene.

```{r, include= FALSE, results= "asis" , message = FALSE, warning = FALSE, echo=FALSE}
# load("C:/Users/sdona/Documents/Duke/702IDS/TeamProjects/02Project/Q1/streetrx.RData")
load("C:\\Users\\deeks\\Documents\\MIDS\\IDS 702_Modeling and representation of data\\Team Assignments\\Datasets\\streetrx.RData")

# choosing needed columns (needed)
needed_cols <- c('ppm','state','USA_region','source','api_temp','form_temp','mgstr','bulk_purchase')
streetrx_ncols <- streetrx[,needed_cols]

# Observing the data set
summary(streetrx_ncols)
head(streetrx_ncols)
colnames(streetrx_ncols)
```

```{r, include=FALSE, results='asis', message=FALSE, warning=FALSE, echo=FALSE}
# choosing the required drug
streetrx_Codeine <- streetrx_ncols[streetrx_ncols['api_temp'] == 'codeine',]

# ommiting missing values
streetrx_cleaned <- na.omit(streetrx_Codeine)

# create new variable for source
unique(streetrx_cleaned$source)
streetrx_cleaned$source_F <- 'Internet'
streetrx_cleaned$source_F[streetrx_cleaned$source == 'Personal'] <-  'Personal'
streetrx_cleaned$source_F[streetrx_cleaned$source == 'Heard it'] <-  'Heard it'
streetrx_cleaned$source_F[streetrx_cleaned$source == ''] <-  'Not Indicated'
streetrx_cleaned$source_F <- factor(streetrx_cleaned$source_F, ordered = FALSE)
streetrx_cleaned$source_F <- relevel(streetrx_cleaned$source_F, ref = "Not Indicated")

## TO change labels for Bulk Purchase 

# create new variable for dosage
str(streetrx_cleaned)
streetrx_cleaned$dosage <- 'medium'
streetrx_cleaned$dosage[streetrx_cleaned$mgstr == 15] <-  'low'
streetrx_cleaned$dosage[streetrx_cleaned$mgstr == 60] <-  'high'
streetrx_cleaned$dosage <- factor(streetrx_cleaned$dosage)
streetrx_cleaned$dosage <- relevel(streetrx_cleaned$dosage, ref = "low")

# convert USA state to other
levels(streetrx_cleaned$state)
levels(streetrx_cleaned$state)[50] <-"Other"
unique(streetrx_cleaned$state)
```

## EDA

The first step in our EDA was to plot the response variable $ppm$ to check whether it follows a normal distribution in order to build a linear regression model. We observed the distribution of $ppm$ is highly skewed to the right. We used a log transformation on ppm to address the skewness. The distribution of log ppm was relatively normal and we decided to move ahead with our EDA with log ppm as our response variable. 

```{r, echo=FALSE,header= FALSE, fig.height=2.0, fig.width=5,fig.align ="center",message = FALSE, warning = FALSE}
p1 = streetrx_cleaned %>%
ggplot(aes(x = ppm, fill = )) +
  geom_histogram(bins = 40, color = "black", linetype = "dashed", fill = "lightblue") +
  labs(title="Distribution of price per milligram for Codeine",y="Frequency", x= "ppm")+
  theme_classic() + theme(plot.title = element_text(hjust = 0.5,size=10),legend.position="none")

p2 = streetrx_cleaned %>%
ggplot(aes(x = log(ppm))) + 
  geom_histogram(bins = 30,color = "black", linetype = "dashed", fill = "lightblue") +  scale_fill_brewer(palette="Blues") +
  scale_fill_viridis(discrete = TRUE) +
  labs(title="Distribution of Log ppm for Codeine",y="Frequency", x= "Log ppm") + 
  theme_classic() + theme(plot.title = element_text(hjust = 0.5,size=10),legend.position="none")


grid.arrange(p1,p2, ncol=2)

```

To explore the data further, we plotted our variables to establish any interesting associations with the response variable. Since all our variables are factor variables, we plotted box plots to identify relationships between our variables.

To establish main effects  we plotted log ppm against the variables $Source$, $Bulk purchase$ and $Dosage$. We did not observe any change in trend in the plots for log ppm vs. Source and Bulk Purchase. We did note a variation in the trend plot for log ppm and dosage indicating an association between the two. However we must also bear in mind that both variables are derived from the price entered by the user for the drug. 

```{r, include=FALSE, echo=FALSE,header= FALSE, fig.height=2.5, fig.width=3.5,fig.align ="center",message = FALSE, warning = FALSE}
# Source vs log(ppm)
# p1 = streetrx_cleaned %>%
# ggplot(aes(x = source_F, y=log(ppm),fill = source_F)) +
#   geom_boxplot() + labs(title="ppm vs Source",
#        x="Source",y="Log ppm") + scale_fill_brewer(palette="Set3")+
#   theme_classic() + theme(legend.position="none",plot.title = element_text(hjust = 0.5,size=10))

# Dosage vs log(ppm)
p2 = streetrx_cleaned %>%
ggplot(aes(x = dosage, y=log(ppm),fill = dosage)) +
  geom_boxplot() + labs(title="Log ppm vs Dosage",
       x="Dosage",y="Log ppm") +scale_fill_brewer(palette="Set3")+
  theme_classic() + theme(legend.position="none",plot.title = element_text(hjust = 0.5,size=10))

# # Bulk-purchase vs log(ppm)
# p3 = streetrx_cleaned %>%
# ggplot(aes(x = bulk_purchase, y=log(ppm),fill = bulk_purchase)) +
#   geom_boxplot() + labs(title="ppm vs Bulk Purchase",
#        x="Bulk Purchase",y="Log ppm") +scale_fill_brewer(palette="Set3")+
#   theme_classic() + theme(legend.position="none",plot.title = element_text(hjust = 0.5,size=10))
# 
grid.arrange(p2, ncol=1)

```

After assessing the relationships between the response and explanatory variables, we went on to further explore the interactions between the explanatory variables . The box plots for interaction between Dosage vs Bulk Purchase and Dosage vs. Source showed no change in trend. In particular, we observed some variation in trend of log(ppm) and bulk_purchase when looked at separately for each source. We concluded to explore this interactions further in our model.

```{r, include = FALSE, out.width="50%",echo=FALSE, header= FALSE,fig.align ="center",message = FALSE, warning = FALSE}
# Dosage vs Bulk Purchase
p1 = streetrx_cleaned %>%
ggplot(aes(x = dosage, y=log(ppm),fill = dosage)) +
  geom_boxplot() + facet_wrap(~bulk_purchase) + labs(title="Dosage vs Bulk Purchase",
       x="Dosage",y="Log ppm") + scale_fill_brewer(palette="Set3")+
  theme_classic() + theme(legend.position="none",plot.title = element_text(hjust = 0.5,size=10),axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

# Dosage vs Source
p2 = streetrx_cleaned %>%
ggplot(aes(x = dosage, y=log(ppm),fill = dosage)) +
  geom_boxplot() + facet_wrap(~source_F) + labs(title="Dosage vs Source",
       x="Dosage",y="Log ppm") +scale_fill_brewer(palette="Set3")+
  theme_classic() + theme(legend.position="none",plot.title = element_text(hjust = 0.5,size=10),axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

# Bulk-purchase vs Source
p3 = streetrx_cleaned %>%
ggplot(aes(x = bulk_purchase, y=log(ppm),fill = bulk_purchase)) +
  geom_boxplot() + facet_wrap(~source_F) + labs(title="Bulk Purchase vs Source",
       x="Bulk Purchase",y="Log ppm") +scale_fill_brewer(palette="Set3")+
  theme_classic() + theme(legend.position="none",plot.title = element_text(hjust = 0.5,size=10))

grid.arrange(p3, ncol=1)

```


We also plotted the response variable against our location variables - State and USA region to establish whether we should include the random intercept for these variables. 

We observed a slight trend change between log ppm and USA region. For state, we saw variation across multiple states. Since states are nested within regions, we decided to assess the impact of location on the price of the drug at a more granular level i.e. at the state level. Hence we included state as our hierarchical variable. 

The state variable has more than 50 levels, therefore to look at the trend we plotted a subset of these states. We filtered states with more than 50 observations in our data and plotted them against log ppm to see if there was any variation. We did see a variation and thus we decided to control our intercept of the model by state.


```{r, out.width="50%",echo=FALSE,header= FALSE,fig.align ="center",message = FALSE, warning = FALSE, fig.height=3.5}
data <- streetrx_cleaned %>% count(state)

# state vs log(ppm) (random intercept)

sample_state <- data[data['n'] > 50,'state']

ggplot(streetrx_cleaned[is.element(streetrx_cleaned$state,sample_state),], 
       aes(x=state, y=log(ppm), fill=state)) + 
  geom_boxplot() + 
  labs(title="Log ppm levels by state", 
       x="State",y="Log ppm") + theme_classic() + 
  theme(legend.position="none",plot.title = element_text(hjust = 0.5,size=10),axis.text.x = element_text(angle = 90))

```
 



We also investigated whether we need to include any random slopes in our model based on the interaction between the main effects and our grouping variable State. We plotted box plots to investigate the associations and concluded that we may need to include random slopes by State for the Source variables and Bulk Purchase variable based on change in trends across states for ppm for these variables.



## __Model__        

To build our model, we first built our baseline linear regression which included all our main effects without controlling any of the intercepts or slopes by state. Next we used step wise selection using AIC to generate our final linear model with main effects. We then included some interaction effects which we thought to be significant, or they answered questions with respect to the study. With the help of anova tests we assessed if these interaction were significant to our model.  We then incorporated our random intercepts and random slopes and tested them again using anova to arrive on our final model.

Our first model included the main effect of every variable. Since all effects are factor variables we did not need to center them to improve our interpretation. Here our response variable is __log ppm__ and the predictors are __source, dosage and bulk purchase__.  Next we used step wise selection using AIC and BIC to assess which variables should we retain in our model. Based on this, we removed the variable source from our model. Given that source was an interesting variable we also tested it using anova and the p value was insignificant at 95% confidence level. 

To ensure our final model is the best fit for our data, we also included the one interaction effect we found interesting during our EDA to the model and used the anova test to conclude whether the interaction between source and bulk purchase had a significant impact on our model or not. However, based on anova the interaction also came out to be insignificant which meant there seemed to be no additional impact of those interactions.

Once we had our linear model, we proceeded to include the random intercepts and slopes that were of interest to us. Based on our EDA we included a varying intercept for the state variable. Further, we also included varying slopes by state for bulk purchase and dosage. In order to analyze whether including varying slopes improved the fit of the model, we used anova to compare each of the varying slope models to our model, which only included the varying intercept. However based on anova, the p value for both the models with varying slopes was insignificant at 95% confidence level indicating that controlling for slopes by state did not improve the fit of our model.

$$
y_{i\ state} = (\beta_0 + \gamma_{0\ state}) + (\beta_1)dosage_{1i\ state} + (\beta_1)bulk\_purchase_{1i\ state} + \epsilon_{i\ state};\ i = 1,...,n_{state};\ state= 1,...,59
$$

```{r, echo=FALSE,include = FALSE, message=FALSE, warning=FALSE, results='asis'}
## MODEL Building
# base model includes all main effects
base_model <- lm(log(ppm) ~ source_F + bulk_purchase + dosage
                 ,data= streetrx_cleaned)

summary(base_model)
#backward selection
null_model <- lm(log(ppm) ~ source_F, data= streetrx_cleaned)
base_model <- lm(log(ppm) ~ source_F + 
                   bulk_purchase + dosage, data= streetrx_cleaned)
Model_backward <- step(null_model,scope = formula(base_model), direction = "both", trace = 0)
Model_backward$call


# both AIC and BIC come up with the same model which contains bulk_purchase and dosage
# we test with anova to ensure that the we should keep source or not and annova removed it

model_with_source <- lm(formula = log(ppm) ~ dosage + bulk_purchase, data = streetrx_cleaned)
model_without_source <- lm(formula = log(ppm) ~ source_F + dosage + bulk_purchase, data = streetrx_cleaned)
anova(model_without_source, model_with_source)

# use to test interaction that was found interesting in the EDA and annova removes it 
model_without_interaction <- lm(formula = log(ppm) ~ dosage + bulk_purchase, data = streetrx_cleaned)
model_with_interaction <- lm(formula = log(ppm) ~ dosage + bulk_purchase + bulk_purchase*source_F, data = streetrx_cleaned)
anova(model_with_interaction, model_without_interaction)



# we control the intercept of state
model_state_controlled <- lmer(log(ppm) ~  dosage + bulk_purchase + 
                                 (1| state), data = streetrx_cleaned)

# control slope for states and test them with anova
model_state_dosage <- lmer(log(ppm) ~  dosage + bulk_purchase + 
                             (dosage| state), data = streetrx_cleaned)

anova(model_state_controlled,model_state_dosage)
# Random Slope insignificant

# checking for varying slope of bulk_purchase 
model_state_bulk_purchase <- lmer(log(ppm) ~  dosage + bulk_purchase + 
                                    (bulk_purchase| state), data = streetrx_cleaned)

anova(model_state_controlled,model_state_bulk_purchase)
# Random Slope insignificant

# checking for varying intercept of Region 
model_state_USA_region <- lmer(log(ppm) ~  dosage + bulk_purchase + 
                                    (1| state) + (1|USA_region) , data = streetrx_cleaned)

anova(model_state_controlled,model_state_bulk_purchase)
# Random Intercept of USA Region insignificant

# we make final model based after all the anova tests and test assumption
final_model <- lmer(log(ppm) ~  dosage + bulk_purchase + 
                      (1| state), data = streetrx_cleaned)
```


## __Model Assessment__        

To assess our final model we checked if the assumptions of Linearity, Normality, Equal variance and Independence were violated. Since all our variables are factor variables, we were unable to verify the linearity assumption.

```{r,include=FALSE,fig.align ="center",echo=FALSE, message=FALSE, warning=FALSE, results='asis'}

resid <- residuals(final_model)
fitted <- fitted(final_model)

```


To check the independence and equal variance assumptions we plotted the residuals against the fitted values. The points seemed randomly distributed with no discernible pattern and the spread of variables seemed constant above and below the line. There did seem to be some points on the x axis that may have violated the equal variance of errors assumptions however, they were only few points and it is safe to say that neither of the above mentioned assumptions were violated. However, this does indicate that there are outliers are present in our data. To check for normality, we plotted the Q-Q plot. For our model we observed that majority of the points lie on the 45 degree line. Both the _Q-Q plot_ and the _Residuals vs fitted plot are shown below.

`````{r, echo=FALSE, message=FALSE, warning=FALSE, results="asis", fig.show="hold",  out.width="50%" ,fig.height= 3.5}

# check for residual against fitted
ggplot(data = streetrx_cleaned, aes(x = fitted, y = resid)) +
  geom_point() + geom_smooth()+
  labs(title = 'Residuals vs Fitted')
#check for normality
ggplot(mapping = aes(sample = resid )) + stat_qq_point(size =2, color = "blue") + stat_qq_line() + xlab("Theortical Quantiles") + ylab("Sample Quantiles") + ggtitle("Normal QQ Plot") +
  theme(plot.title = element_text(hjust = 0.5) )

```

To check if outliers were affecting our model we removed them from our data and ran the model again. However, the standard estimates and their p-values did not change and hence we can conclude that the outliers were not affecting our model.

## __Model Interpretations__

We found out that all our explanatory variables had a significant effect on log_ppm. To make the interpretation of the standard estimates simpler we exponentiate them and measure the effect on price. We notice that for low dosage and drug not being purchase in bulk the price was 0.33 USD. If the drug was purchased in high dosage the price per milligram decreased by 65% compared to if it was purchase in low dosage. When purchase in medium dosage the price/mg decreases by 51%. If the drug was purchase in bulk, the price/mg dropped by 87%. We also note that controlling our intercept for state only explains 13.2% of the variation in log(ppm). The summary of our model is shown below.
```{r, echo=FALSE, message=FALSE, warning=FALSE, results='asis', fig.height=3}
final_model <- lmer(log(ppm) ~  dosage + bulk_purchase + 
                      (1| state), data = streetrx_cleaned)
stargazer(final_model, title = "Hierarchical Model Summary", float = TRUE, no.space=TRUE, header=FALSE, single.row=TRUE, font.size="small", digits = 2, ci=TRUE, ci.level=0.95)
```

Looking at the dot plot of random effects we notice that the the drug Codeine is found to be cheaper in the states Michigan, Missouri, Illinois and Texas. The confidence interval of the random effect for the other states contains zero, hence, we can say that the price of the drug does not vary significantly for them. The dotplot is shown below.

```{r,echo=FALSE, message=FALSE, warning=FALSE, results='asis', fig.height= 6.7, fig.align='center'}
# dotplot for random effects
dotplot(ranef(final_model, condVar= TRUE))$state
```

## __Limitations and Conclusions__

There are a few potential limitations in our model. Firstly, we removed 919 data observations when dealing with missing values. This can be avoided using missing value imputation methods. The second major limitation is that the data used is not reliable as it is crowd sourced and any one can put in any value for the price of the drug.

To conclude, we note that the drug Codeine can be bought for a cheaper price in the Michigan, Missouri, Illinois and Texas states. Purchasing the drug in bulk quantity and at high dosages can also reduce the price of the drug. It was surprising to find out that the source variable did not have a significant affect on the price/mg as we initially hypothesized that prices on the internet to be more expensive than the prices they observed through personal experiences.

# __*Part II: Voting in NC (2020 General Elections)*__
## __*Deekshita Saikia as Programmer/Writer, Tego Chang as Programmer/Writer, and Sydney Donati-Leach as Programmer/Writer*__

## __Summary__
This analysis is to investigate the potential factors, especially the demographic ones, that affect the turnout rates of the US 2020 General elections in North Carolina. During the process, data cleaning, aggregation, and merging have been performed to combine the registered voters information with the actual voter turnouts. Exploratory data analysis was then performed and the effects of demographic factors on the actual turnouts were examined. The finalized hierarchical model helps us dive into how demographics like age impact the turnout rates in the election, and serves to provide a possible explanation as to why the Republicans outperform the Democrats in certain counties. 

## __Introduction__
It is widely acknowledged that the voting behaviors in the election are related to several factors, e.g., demographic factors, location, or the party you are affiliated to. This analysis constructs a hierarchical model to answer the following questions:

- How did different demographic subgroups vote in the 2020 general elections?
- Did the odds of voting differ by county? Which counties differ the most?
- How did the turnout rate differ between males and females for different parties?
- How did the turnout rate differ among age groups for different parties?

## __Data__

### Data Pre-Processing

The data used for this analysis was extracted from two files available with The North Carolina State Board of Elections (NCSBE), which is the agency charged with the administration of the elections process and campaign finance disclosure and compliance. One file contains the voter registration records, while the other contains data on the actual turnout (<https://www.ncsbe.gov/index.html>, <https://www.ncsbe.gov/results-data>). The code book can be found in the appendix.

The unit of observation in the registered voters file is $county\_desc$, $precinct\_abbrv$, $vtd\_abbrv$, $party\_cd$, $race\_code$, $ethnic\_code$, $sex\_code$ and $age$. The turnouts file had data at a more granular level ($voting\_method$), and it was aggregated to match the unit of observation in the registered voter file. The registered voters file had 592,265 observations, while the turnouts file had 928,532 observations. Post aggregation of the turnouts file, there were 492,567 observations remaining. The actual turnout numbers were then merged with the total voter file to create a model ready dataset. The dataset was further reduced to a sample of 25 counties, post which we were left with 13,162 observations, grouped at a $county\_desc$, $party\_cd$, $race\_code$, $ethnic\_code$, $sex\_code$ and $age$ level, with the total number of registered voters and turnouts in demographic groups represented by these characteristics.

```{r echo=FALSE,  message=FALSE, warning=FALSE, results='asis'}
# Reading in libraries
library(ggplot2)
library(rms)
library(arm)
library(e1071)
library(caret)
library(pROC)
library(ggdark)
library(ggeasy)
library(tidyverse)
library(viridis)
library(sjPlot)
library(xtable)
library(stargazer)
```

```{r echo=FALSE,  message=FALSE, warning=FALSE, results='asis', include=FALSE}
# Reading in datasets
# voter <- read.csv("C:/Users/sdona/Documents/Duke/702IDS/TeamProjects/02Project/Q2/voter_stats_20201103.txt", header=TRUE, sep='\t')
# history <- read.csv("C:/Users/sdona/Documents/Duke/702IDS/TeamProjects/02Project/Q2/history_stats_20201103.txt", header=TRUE, sep='\t')

voter <- read.csv("C:\\Users\\deeks\\Documents\\MIDS\\IDS 702_Modeling and representation of data\\Team Assignments\\Datasets\\voter_stats_20201103.txt", header=TRUE, sep='\t')
history <- read.csv("C:\\Users\\deeks\\Documents\\MIDS\\IDS 702_Modeling and representation of data\\Team Assignments\\Datasets\\history_stats_20201103.txt", header=TRUE, sep='\t')


# Preliminary check of the datasets
head(voter)
summary(voter)
str(voter)

head(history)
summary(history)
str(history)

# Dropping unwanted columns from both datasets
drop <- c("election_date","stats_type","update_date")
voter <- voter[, !names(voter) %in% drop]
history <- history[, !names(history) %in% drop]

# Aggregating the history dataset to match the level
# (of uniqueness of obs) of the voter dataset
agg_history <- aggregate(list(turnout=history$total_voters),
                         list(county_desc=history$county_desc,
                              party_cd=history$voted_party_cd,
                              age=history$age, race_code=history$race_code,
                              ethnic_code=history$ethnic_code,
                              sex_code=history$sex_code,
                              precinct_abbrv=history$precinct_abbrv,
                              vtd_abbrv=history$vtd_abbrv), sum)

# Merging the two datasets on the following cols:
# county_desc,	precinct_abbrv,	vtd_abbrv,	party_cd,
# race_code,	ethnic_code,	sex_code,	age
merged <- left_join(voter, agg_history, by = NULL, copy = FALSE)

# Replacing nulls in turnout by zeroes
merged$turnout[is.na(merged$turnout)] <- 0

# quick QC on the voter numbers before and after merge --> match!
agg_voter <- aggregate(voter$total_voters,
                       list(Age=voter$age,Party=voter$party_cd),sum)
agg_data <- aggregate(merged$total_voters,
                      list(Age=merged$age,Party=merged$party_cd),sum)

# Checking the proportion of voters who turned up to vote --> ~75%
sum(merged$turnout)/sum(merged$total_voters)

# Taking a sample of 25 counties from the entire dataset
# and filtering dataset on those counties
set.seed(123) #set your own seed to be able to replicate results
all_counties <- unique(merged[c("county_desc")])
county_sample <- c(sample(all_counties$county_desc,size=25,replace=F))
voters_reduced <- merged[is.element(merged$county_desc,county_sample),]

voters_reduced_agg <- aggregate(list(total_voters = voters_reduced$total_voters
                             ,turnout = voters_reduced$turnout
                            ),
                        by=list(county_desc=voters_reduced$county_desc,
                                     party_cd=voters_reduced$party_cd,
                                     age=voters_reduced$age,
                                     race_code=voters_reduced$race_code,
                                     ethnic_code=voters_reduced$ethnic_code,
                                     sex_code=voters_reduced$sex_code
                                     ),FUN=sum)

voters_reduced_agg$county_desc <- factor(voters_reduced_agg$county_desc)
voters_reduced_agg$party_cd <- factor(voters_reduced_agg$party_cd)
voters_reduced_agg$age <- factor(voters_reduced_agg$age)
voters_reduced_agg$race_code <- factor(voters_reduced_agg$race_code)
voters_reduced_agg$ethnic_code <- factor(voters_reduced_agg$ethnic_code)
voters_reduced_agg$sex_code <- factor(voters_reduced_agg$sex_code)
voters_reduced_agg$turnout <- as.integer(voters_reduced_agg$turnout)

# voters_reduced_agg$temp <- voters_reduced_agg$turnout
# voters_reduced_agg$temp[voters_reduced_agg$temp > voters_reduced_agg$total_voters] <- voters_reduced_agg$total_voters


voters_reduced_agg$turnout_rate <- voters_reduced_agg$turnout/voters_reduced_agg$total_voters
voters_reduced_agg$turnout_rate[voters_reduced_agg$turnout_rate > 1] <- 1
voters_reduced_agg$newcol <- voters_reduced_agg$turnout_rate * voters_reduced_agg$total_voters
voters_reduced_agg = subset(voters_reduced_agg, select = -c(turnout))
names(voters_reduced_agg)[names(voters_reduced_agg)=="newcol"] <- "turnout"

str(voters_reduced_agg)
unique(voters_reduced_agg$party_cd)
unique(voters_reduced_agg$race_code)
unique(voters_reduced_agg$age)

# The unique counties in our dataset are:
# CUMBERLAND   LEE          ORANGE       UNION        WATAUGA      CABARRUS     HARNETT      NEW HANOVER 
# SCOTLAND     DAVIDSON     HAYWOOD      PERSON       ROWAN        WILSON       COLUMBUS     NORTHAMPTON 
# PENDER       TYRRELL      ALEXANDER    WARREN       POLK         GATES        MACON        TRANSYLVANIA
# HYDE
```

## __EDA__

Our EDA is split into 4 different sections.  First, we will look at a plot of our hierarchy, county, to determine if it has varying intercept or varying slope.  Second, we will look at our main effects, which are all factor variables in our data, so we will only look at boxplots.  Third, we will look at all of the interactions with our main effects, again by analyzing boxplots.  Finally, we will look at the interactions between our main effects and our set hierarchy to see if we need to control for varying slope.

When we look at county, the hierarchy in our data, it clearly varies from county to county. Alexander, Haywood and Hyde have high voter turnout compared to Columbus, Cumberland, Scotland and Wilson.  Therefore, we will move forward knowing that we need to include varying intercept in our model building. Next, when we look at our main effects, we can pull some basic information from the boxplots. For example, older age groups coming out to vote more than younger age groups, or that most people choose not disclose their sex when registering to vote.

```{r echo=FALSE,  message=FALSE, warning=FALSE, results='asis', fig.height=4.5, fig.width=8}
################## varying intercept ##########################
# Plot county vs turnout 
ggplot(voters_reduced_agg,aes(x=county_desc, y=turnout_rate, fill=county_desc)) +
  geom_boxplot() +
  scale_fill_viridis(discrete = TRUE) + labs(title="Turnout Rate vs Counties", x="Counties",y="Turnout Rate") + 
  theme_classic() + theme(legend.position="none", plot.title = element_text(hjust = 0.5,size=10),axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
```


When we go through all of the interactions of our main effects, we have to consider both the trends in the boxplots as well as the number of observations.  This is because a changing trend from one category to the next could be due to a lack of observations rather than an interesting interaction taking place.  One example of this is the race of P (Pacific Islander).  We sometimes have zero observations of this race when we split it up into different categories, so we have to look at changing trends without consideration for it. This becomes complicated when we also want to look at the interaction between race and party because there are two parties with far fewer observations: CST and GRE. Now we have three different categories that we should *not* take into consideration when looking at trends. Due to these limitations, we decided not to include this interaction in our model building. On the other hand, there are two interactions of high importance to us: age versus party and sex versus party.  These are questions of interest, so regardless of what kind of trend we see, we must include them when model building. We did see that there was a higher median for republicans of ages 26-40 as compared to democrats of the same age group, so we will keep that in mind moving forward.

```{r echo=FALSE,  message=FALSE, warning=FALSE, results='asis',fig.height=3.5, fig.width=3.5}
# # frequencies for race vs party 
print(xtable(table(voters_reduced_agg$race_code, voters_reduced_agg$party_cd)), comment = FALSE)
# ################## main effects ##########################
# # Plot party vs turnout 
# ggplot(voters_reduced_agg,aes(x=party_cd, y=turnout_rate, fill=party_cd)) +
#   geom_boxplot() + #coord_flip() +
#   # scale_fill_brewer(palette="Greens") +
#   scale_fill_viridis(discrete = TRUE) +
#   labs(title="Turnout Rate vs Party Affiliation",
#        x="Party Affiliation",y="Turnout Rate") + 
#   theme_classic() + theme(legend.position="none")
# 
# # Plot age group vs turnout 
# ggplot(voters_reduced_agg,aes(x=age, y=turnout_rate, fill=age)) +
#   geom_boxplot() + #coord_flip() +
#   # scale_fill_brewer(palette="Greens") +
#   scale_fill_viridis(discrete = TRUE) +
#   labs(title="Turnout Rate vs Age",
#        x="Age",y="Turnout Rate") + 
#   theme_classic() + theme(legend.position="none")
# 
# # Plot race vs turnout 
# ggplot(voters_reduced_agg,aes(x=race_code, y=turnout_rate, fill=race_code)) +
#   geom_boxplot() + #coord_flip() +
#   # scale_fill_brewer(palette="Greens") +
#   scale_fill_viridis(discrete = TRUE) +
#   labs(title="Turnout Rate vs Race",
#        x="Race",y="Turnout Rate") + 
#   theme_classic() + theme(legend.position="none")
# 
# # Plot ethnicity vs turnout 
# ggplot(voters_reduced_agg,aes(x=ethnic_code, y=turnout_rate, fill=ethnic_code)) +
#   geom_boxplot() + #coord_flip() +
#   # scale_fill_brewer(palette="Greens") +
#   scale_fill_viridis(discrete = TRUE) +
#   labs(title="Turnout Rate vs Ethnicity",
#        x="Ethnicity",y="Turnout Rate") + 
#   theme_classic() + theme(legend.position="none")
# 
# # Plot sex vs turnout
# ggplot(voters_reduced_agg,aes(x=sex_code, y=turnout_rate, fill=sex_code)) +
#   geom_boxplot() + #coord_flip() +
#   # scale_fill_brewer(palette="Greens") +
#   scale_fill_viridis(discrete = TRUE) +
#   labs(title="Turnout Rate vs Sex",
#        x="Sex",y="Turnout Rate") + 
#   theme_classic() + theme(legend.position="none")


##################### interactions #####################################
# Plot sex vs turnout by party- MAYBE INCLUDE
# ggplot(voters_reduced_agg,aes(x=sex_code, y=turnout_rate, fill=sex_code)) +
#   geom_boxplot() + #coord_flip() +
#   # scale_fill_brewer(palette="Greens") +
#   scale_fill_viridis(discrete = TRUE) +
#   labs(title="Turnout Rate vs Sex by Party Affiliation",
#        x="Sex",y="Turnout Rate") + 
#   theme_classic() + theme(legend.position="none", plot.title = element_text(hjust = 0.5,size=10)) +
#   facet_wrap(~party_cd, ncol=3)
# 
# # Plot sex vs turnout by age
# ggplot(voters_reduced_agg,aes(x=sex_code, y=turnout_rate, fill=sex_code)) +
#   geom_boxplot() + #coord_flip() +
#   # scale_fill_brewer(palette="Greens") +
#   scale_fill_viridis(discrete = TRUE) +
#   labs(title="Turnout Rate vs Sex by Age group",
#        x="Sex",y="Turnout Rate") + 
#   theme_classic() + theme(legend.position="none") +
#   facet_wrap(~age, ncol=4)
# 
# # Plot sex vs turnout by race
# ggplot(voters_reduced_agg,aes(x=sex_code, y=turnout_rate, fill=sex_code)) +
#   geom_boxplot() + #coord_flip() +
#   # scale_fill_brewer(palette="Greens") +
#   scale_fill_viridis(discrete = TRUE) +
#   labs(title="Turnout Rate vs Sex by Race",
#        x="Sex",y="Turnout Rate") + 
#   theme_classic() + theme(legend.position="none") +
#   facet_wrap(~race_code, ncol=4)
# 
# # Plot sex vs turnout by ethnicity
# ggplot(voters_reduced_agg,aes(x=sex_code, y=turnout_rate, fill=sex_code)) +
#   geom_boxplot() + #coord_flip() +
#   # scale_fill_brewer(palette="Greens") +
#   scale_fill_viridis(discrete = TRUE) +
#   labs(title="Turnout Rate vs Sex by Ethnicity",
#        x="Sex",y="Turnout Rate") + 
#   theme_classic() + theme(legend.position="none") +
#   facet_wrap(~ethnic_code, ncol=3)
#
# # Plot age vs turnout by party- MAYBE INCLUDE
# ggplot(voters_reduced_agg,aes(x=age, y=turnout_rate, fill=age)) +
#   geom_boxplot() + #coord_flip() +
#   # scale_fill_brewer(palette="Greens") +
#   scale_fill_viridis(discrete = TRUE) +
#   labs(title="Turnout Rate vs Age group by Party Affiliation",
#        x="Age Group",y="Turnout Rate") + 
#   theme_classic() + theme(legend.position="none", plot.title = element_text(hjust = 0.5,size=10),axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) +
#   facet_wrap(~party_cd)
#
# 
# # Plot race vs turnout by party
# ggplot(voters_reduced_agg,aes(x=race_code, y=turnout_rate, fill=race_code)) +
#   geom_boxplot() + #coord_flip() +
#   # scale_fill_brewer(palette="Greens") +
#   scale_fill_viridis(discrete = TRUE) +
#   labs(title="Turnout Rate vs Race by Party Affiliation",
#        x="Race",y="Turnout Rate") + 
#   theme_classic() + theme(legend.position="none") +
#   facet_wrap(~party_cd, ncol=3)


```

Finally, we looked at interactions of our main effects and county.  We did find the interaction between county and age or the interaction between county and ethnicity to be as interesting because the trend only changed in 8 or 9 counties out of all 25. When we look at interactions with race and party, we must still keep in mind the low count of observations for some categories. If we do not consider race P when analyzing our race interaction, the trend changes from one county to the next.  If we do not consider the CST or GRE parties when analyzing the party interaction, we also see differences in the median from one plot to the next. Even though both of these interactions are interesting, we had to choose which one we wanted to focus on so that we could interpret our final model. We made the decision that we should control the random slope for county versus party, and we will further discuss this in our model building section.

```{r echo=FALSE,  message=FALSE, warning=FALSE, results='asis',fig.height=5, fig.width=8}
################## random slope ##############################
# Plot age vs turnout by county
# ggplot(voters_reduced_agg,aes(x=age, y=turnout_rate, fill=age)) +
#   geom_boxplot() + #coord_flip() +
#   # scale_fill_brewer(palette="Greens") +
#   scale_fill_viridis(discrete = TRUE) +
#   labs(title="Turnout Rate vs Age by County",
#        x="Age",y="Turnout Rate") + 
#   theme_classic() + theme(legend.position="none") +
#   facet_wrap(~county_desc, ncol=5)

# Plot party vs turnout by county
ggplot(voters_reduced_agg,aes(x=party_cd, y=turnout_rate, fill=party_cd)) +
  geom_boxplot() + #coord_flip() +
  # scale_fill_brewer(palette="Greens") +
  scale_fill_viridis(discrete = TRUE) +
  labs(title="Turnout Rate vs Party Affiliation by County",
       x="Party Affiliation",y="Turnout Rate") + 
  theme_classic() + theme(legend.position="none", 
  plot.title = element_text(hjust = 0.5,size=10),
  axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) + 
  facet_wrap(~county_desc, ncol=5)

# Plot race vs turnout by county
# ggplot(voters_reduced_agg,aes(x=race_code, y=turnout_rate, fill=race_code)) +
#   geom_boxplot() + #coord_flip() +
#   # scale_fill_brewer(palette="Greens") +
#   scale_fill_viridis(discrete = TRUE) +
#   labs(title="Turnout Rate vs Race by County",
#        x="Race",y="Turnout Rate") +
#   theme_classic() + theme(legend.position="none", plot.title = element_text(hjust = 0.5,size=10),axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1)) + facet_wrap(~county_desc, ncol=5)
#
# # Plot ethinicity vs turnout by county
# ggplot(voters_reduced_agg,aes(x=ethnic_code, y=turnout_rate, fill=ethnic_code)) +
#   geom_boxplot() + #coord_flip() +
#   # scale_fill_brewer(palette="Greens") +
#   scale_fill_viridis(discrete = TRUE) +
#   labs(title="Turnout Rate vs Ethnicity by County",
#        x="Ethnicity",y="Turnout Rate") + 
#   theme_classic() + theme(legend.position="none") +
#   facet_wrap(~county_desc, ncol=5)
# 
# # Plot sex vs turnout by county
# ggplot(voters_reduced_agg,aes(x=sex_code, y=turnout_rate, fill=sex_code)) +
#   geom_boxplot() + #coord_flip() +
#   # scale_fill_brewer(palette="Greens") +
#   scale_fill_viridis(discrete = TRUE) +
#   labs(title="Turnout Rate vs Sex by County",
#        x="Sex",y="Turnout Rate") + 
#   theme_classic() + theme(legend.position="none") +
#   facet_wrap(~county_desc, ncol=5)
# 
# 
# # TODO
# # frequencies for age vs party
# table(voters_reduced_agg$age, voters_reduced_agg$party_cd)
# 
# # frequencies for age vs party
# table(voters_reduced_agg$sex_code, voters_reduced_agg$party_cd)
# 
# # frequencies for sex vs race - observations against race "P" very few
# table(voters_reduced_agg$sex_code, voters_reduced_agg$race_code)
# 
# # frequencies for sex vs ethnicity - very similar trends
# table(voters_reduced_agg$sex_code, voters_reduced_agg$ethnic_code)
# 
# # frequencies for race vs county 
# table(voters_reduced_agg$race_code, voters_reduced_agg$county_desc)
# 
# # frequencies for age vs county 
# table(voters_reduced_agg$age, voters_reduced_agg$county_desc)
# 
# # frequencies for party vs county 
# table(voters_reduced_agg$party_cd, voters_reduced_agg$county_desc)
# 
# # frequencies for ethnicity vs county 
# table(voters_reduced_agg$ethnic_code, voters_reduced_agg$county_desc)

```

```{r echo=FALSE,  message=FALSE, warning=FALSE, results='asis', include=FALSE}
# start_time <- Sys.time()
# model1 <- glmer(cbind(turnout, total_voters-turnout) ~
#                   age + party_cd + race_code + ethnic_code + sex_code +
#                   age: party_cd + sex_code:party_cd + (1 | county_desc),
#                 family=binomial, data=voters_reduced_agg, control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e5)))
# end_time <- Sys.time()
# print(paste("The model training time:" , end_time - start_time))
# 
# 
# summary(model1)
# tab_model(model1)
# dotplot(ranef(model1, condVar=TRUE))
```

```{r echo=FALSE,  message=FALSE, warning=FALSE, results='asis'}
#start_time <- Sys.time()
model2 <- glmer(cbind(turnout, total_voters-turnout) ~
                  age + party_cd + race_code + ethnic_code + sex_code +
                  age: party_cd + sex_code:party_cd + (party_cd | county_desc),
                family=binomial(link="logit"), data=voters_reduced_agg, control=glmerControl(optimizer="bobyqa",optCtrl=list(maxfun=2e5)))
#end_time <- Sys.time()
#print(paste("The model training time:" , end_time - start_time))

#summary(model2)
#tab_model(model2)
#dotplot(ranef(model2, condVar=TRUE))
```
## __Model__

Model selection was performed by accounting for different interactions and effects, which included both random and fixed effects. Our main interactions of interest are analyzing how the turnouts differed by the sexes, and if party affiliations played a role. We are also interested in exploring by the turnouts differed for the age groups for different party affiliations.

We fit a hierarchical model to explore the random effects that different counties may contribute to the model. Counties are used as the only hierarchy. In addition, random slopes for party affiliations were also considered. The model with random intercepts by county was then compared to the model with random slopes for party affiliations with an ANOVA Chi-squared test, and we observe that incorporating the random slope significantly improves model fit.

The final model equation is as follows:

$$ y_i|x_i \hspace {1mm}{\sim} \hspace {1mm} Bernoulli (\pi_i);\hspace {1mm} i = 1,2,\ldots, 13162; \hspace {1mm} j = 1,2, \ldots, 25 $$ 

$$
(\beta_0 + \gamma_{0j|i|}) +  \beta_1 * x_{i1} + \beta_2*x_{i2} + \beta_3*x_{i3} + \beta_4*x_{i4} + \beta_5*x_{i5} + \beta_6*x_{i6} + (\beta_7 + \gamma_{1j|i|}) x_{i7};
$$
where, $x_{i1}$ is $age$, $x_{i2}$ is $race\_code$, $x_{i3}$ is $ethnic\_code$, $x_{i4}$ is $sex\_code$, $x_{i5}$ is the interaction effect of $age$ and $party\_code$, $x_{i6}$ is the interaction between $sex\_code$ and $party\_cd$, and $x_{i7}$ is $party\_cd$.

$$ \gamma_{0j}, \gamma_{1j} \hspace {1mm}{\sim} \hspace {1mm} N_2(0, \Sigma)  $$

In this model, age group 18 - 25 year olds, the Constitution Party, the Asian race, the Hispanic/Latino ethnicity and the female sex are used as baseline factors that are absorbed into the intercept, for ease of interpretation of the impact of these predictors in voter turnouts. All the predictors and the interaction terms are categorical, and a total of 44 distinct factors can be seen in the final model. We observe that the fixed effects of the model are significant at the 5% level. The largest z-values can be observed for $race\_code$, $ethnic\_code$ and $age$, signifying that these factors are the strongest predictors of whether a person if likely to turn up to vote in the elections.

```{r echo=FALSE,  message=FALSE, warning=FALSE, fig.align='center', results='asis', out.width="80%"}
dotplot(ranef(model2, condVar=TRUE))
```

From the dotplot of the random effects above, we observe that introducing the random slope effect of party shows that the log odds of a person voting across different counties differs greatly by the party they are affiliated to. Counties like Alexander, Cabarrus, Orange and Union have odds of voting which are significantly different than zero. People voting for the Green Party have highly varying odds, but this can also be attributed to the lower number of observations recorded against this party. Although the plot confirms that parties account for a lot of the variance in the voting odds we see across counties, it still does not explain all the variation in the model.


## __Conclusion__
The answers to our questions of interest are: 

- The odds of turnout for males is 1.06 times compared to females, which is six percent higher. However, it is not statistically significant. The odds of turnout for age group 41 to 65 is found to be the highest, which is 2.7 times compared to the age group 18 to 25. With respect to race, when the Asian race is set as the baseline, the odds of turnout for Pacific Islanders, Undesignated, and White have higher odds of turnout. However, there are very few observations for Pacific Islanders. With respect to ethnic groups, when the Hispanic/Latino category is set as the baseline, the non-hispanic/non-latino category have higher odds of turnout. 

- The odds of voting differ by county in 2020 from our EDA, so we added varying intercepts by county in our model. Further, we also observed changes in trends when checking if there is an interaction between party and county. Thus, varying slopes by county were also added to the model. In this case, the varying intercept in our model is 0, but if we select a party, say Democrat, Wake county has the highest odds of turnout, while Randolph and Mcdowell have the lowest ones.

- Observing the interaction between age and party, there are many factors that are statistically significant. One of the interpretations for these combinations is that the odds of turnout for age group 26 to 40 who vote for Democrats is 2.03 times, increasing by 103%, compared to the age group 18 to 25 who vote for CST. 

Besides the above questions of interest, we further dive into the voters' age groups and investigate which age group has a higher impact on the actual turnouts between Democrats and Republicans. Observing the interaction between age and party, the 26 to 40 age group is the only statistically significant factor compared with the two other age groups, with age group 18 to 25 as the baseline. Then, we further calculate the odds of turnout between the Democrats and Republicans for this age group, and we observe that the turnouts for Republicans is higher than for Democrats, with odds of turnout observed at 2.41 for the former and 2.05 for the latter when the baseline is the age group of 18 to 25 voting for CST. Another possible explanation behind this might also be the fact that Democrats and Republicans are the two biggest parties, and hence, many observations are available against these parties, compared to the Constitution and Green parties.

### Limitations

One limitation of this analysis is that, the NCSBE does not provide the exact difference between the variables $party\_cd$ and $voted\_party\_cd$ in the actual voter turnouts file. If voters changed their party affiliation at the time of casting their votes, this information is not captured in the dataset, and would not tally with the registered voter numbers. In addition, a random effect model with a varying slope and a varying intercept leads to very complicated interpretations of the model parameters. Since the data is grouped at a combination of different demographics, which makes it granular, we observe that not all groupings have enough observations recorded against them to fit a model on. Certain categories could be aggregated out so that there are sufficient observations against each grouping. 